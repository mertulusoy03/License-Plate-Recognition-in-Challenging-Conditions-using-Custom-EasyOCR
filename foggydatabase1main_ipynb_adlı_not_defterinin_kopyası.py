# -*- coding: utf-8 -*-
"""foggyDataBase1main.ipynb adlı not defterinin kopyası

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kI-dwrkBDV0OMy3lFPWAAR5kypSm8ZQu
"""

from google.colab import drive
drive.mount('/content/drive/')
!ls /content/drive/MyDrive
!ls /content/drive/MyDrive/Colab

import os
import pandas as pd
import numpy as np
folder_paths = [
    "/content/drive/MyDrive/Colab/foggy",
    "/content/drive/MyDrive/Colab/dortmund"
]

folder_path = "/content/drive/MyDrive/Colab/foggy"
folder_path2 = "/content/drive/MyDrive/Colab/dortmund"
# Klasördeki görüntüleri listele
image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
image_files2 = [f for f in os.listdir(folder_path2) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
print(f"Database1 için Toplam Görüntü Sayısı: {len(image_files)}")

# İlk birkaç görüntüyü kontrol et
print("Database1 :")
print(image_files[:5])
!ls /content/drive/MyDrive/Colab/foggy/
print(f"Database2 için Toplam Görüntü Sayısı: {len(image_files2)}")
print("Database2 :")
print(image_files2[:5])
!ls /content/drive/MyDrive/Colab/dortmund/

import os
import pandas as pd
import numpy as np


folder_paths = [
    "/content/drive/MyDrive/Colab/foggy",
    "/content/drive/MyDrive/Colab/dortmund"
]

for folder_path in folder_paths:
    print(f"Processing folder: {folder_path}")

    # Klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Total images found: {len(image_files)}")

    # Dosyalardan numaraları çıkarma
    image_data = []
    for file_name in image_files:
        try:
            number = int(''.join(filter(str.isdigit, file_name)))
        except ValueError:
            number = None
        image_data.append({"File Name": file_name, "Original Number": number})

    # DataFrame oluştur ve işle
    df = pd.DataFrame(image_data).dropna(subset=["Original Number"])
    df["Original Number"] = df["Original Number"].astype(int)
    df = df.sort_values(by="Original Number").reset_index(drop=True)
    df["Mapped Number"] = np.linspace(1, len(df), len(df)).astype(int)

    # Her klasöre özel Excel dosyası kaydet
    output_path = os.path.join(folder_path, "image_mapped_list.xlsx")
    df.to_excel(output_path, index=False)
    print(f"Excel dosyası kaydedildi: {output_path}")

!pip install tabulate
!pip install openpyxl
from tabulate import tabulate

# Kaydedilen Excel dosyalarını oku ve yazdır
for i, folder_path in enumerate(folder_paths, start=1):
    output_path = os.path.join(folder_path, "image_mapped_list.xlsx")
    if os.path.exists(output_path):  # Dosyanın varlığını kontrol et
        df = pd.read_excel(output_path)

        # Hangi veri seti olduğunu belirtiyorum çünkü özel isimler açıklığı engelliyordu.
        database_label = f"Database{i}"  # Database1, Database2 gibi etiketler

        # Tabloyu yazdır
        print(f"\n\n=== {database_label}: {folder_path} ===")
        print(tabulate(df, headers="keys", tablefmt="grid"))
        print("\n" + "="*50 + "\n")  # Görsel ayrım için
    else:
        print(f"Excel dosyası bulunamadı: {output_path}")

"""***`KOD BAŞLAR`***"""

pip uninstall -y torch torchvision torchaudio

!nvcc --version

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

!ls /usr/local | grep cuda

!export CUDA_HOME=/usr/local/cuda-11.8
!export PATH=$CUDA_HOME/bin:$PATH
!export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

!nvcc --version

import torch
import torchvision
print("Torch version:", torch.__version__)
print("Torchvision version:", torchvision.__version__)
print("CUDA available:", torch.cuda.is_available())
print("CUDA version:", torch.version.cuda)

pip install easyocr

pip install python-Levenshtein

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd

# Daha önce kaydedilen Excel dosyasından ground truth bilgilerini okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Tüm sonuçları saklamak için bir liste
results_list_without_filters = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)



#!!!
#!!!
#!!!

#

# Benzerlik oranı hesaplama fonksiyonu
def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Her veri seti için işlemler
for i, folder_path in enumerate(folder_paths, start=1):
    # Her klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        # Görüntü yolu
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Görüntüyü oku ve RGB formatına çevir
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # OCR işlemi
            results = reader.readtext(image_rgb, detail=1)
            detected_texts = [result[1] for result in results]

            if not detected_texts:
                print(f"No text detected for {image_name}.")
                detected_texts = ["NO DETECTION"]

            # OCR sonuçlarını yazdır ve bounding box çiz
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            # Bounding box'lı görüntüyü göster
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            # Ground Truth bilgisi kontrolü
            ground_truth = ground_truth_dict.get(image_name, "NA")  # Daha önce kayıtlıysa al, yoksa "NA" kullan
            if ground_truth == "NA":
                print(f"Ground truth bilgisi bulunamadı, lütfen manuel giriş yapın: {image_name}")
                continue
#!!!


#!!!
            # Benzerlik oranını hesapla
            similarity_scores = [
                calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts
            ]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # Filtrelenmemiş sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts,
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Confidence Scores": [],
                "Max Similarity (%)": 0
            })

# Sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)

# DataFrame'i baştan görselleştir
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())  # İlk 5 kaydı göster

output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_results_with_similarity.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd
import re

# Daha önce kaydedilen Excel dosyasından ground truth bilgilerini okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Sonuçları saklamak için iki liste
results_list_without_filters = []  # Ham sonuçlar
result_list_normalized = []        # Normalleştirilmiş sonuçlar

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# Metni normalizasyon yapan fonksiyon (belirttiğim özel karakterlerle)
def normalize_text(text):
    text = text.lower()  # Büyük-küçük harf duyarlılığını kaldır
    text = text.replace(" ", "")  # Boşlukları kaldır
    # Belirtilen özel karakterleri temizle
    for char in ['*', "'", '"', '@','?', ';', '>', '<', '_', '-','(', ')','%', '&', '[',']']:
        text = text.replace(char, '')
    return text

# Benzerlik oranı hesaplama fonksiyonu
def calculate_similarity(ground_truth, detected):
    ground_truth_normalized = normalize_text(ground_truth)
    detected_normalized = normalize_text(detected)
    return (1 - distance(ground_truth_normalized, detected_normalized) /
            max(len(ground_truth_normalized), len(detected_normalized))) * 100

# Her veri seti için işlemler
for i, folder_path in enumerate(folder_paths, start=1):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # OCR işlemi
            results = reader.readtext(image_rgb, detail=1)
            detected_texts_raw = [result[1] for result in results]  # Ham metinler
            detected_texts_normalized = [normalize_text(result[1]) for result in results]  # Normalleştirilmiş metinler

            if not detected_texts_raw:
                print(f"No text detected for {image_name}.")
                detected_texts_raw = ["NO DETECTION"]
                detected_texts_normalized = ["NO DETECTION"]

            # OCR sonuçlarını yazdır ve bounding box çiz (ham metinle)
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            ground_truth = ground_truth_dict.get(image_name, "NA")
            if ground_truth == "NA":
                print(f"Ground truth bilgisi bulunamadı, lütfen manuel giriş yapın: {image_name}")
                continue

            # Benzerlik oranını hesapla (normalleştirilmiş metinle)
            similarity_scores = [
                calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts_normalized
            ]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # Ham sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_raw,  # Ham metinler
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity
            })

            # Normalleştirilmiş sonuçları kaydet
            result_list_normalized.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_normalized,  # Normalleştirilmiş metinler
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            # Hata durumunda her iki listeye ekle
            error_entry = {
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Confidence Scores": [],
                "Max Similarity (%)": 0
            }
            results_list_without_filters.append(error_entry)
            result_list_normalized.append(error_entry)

# Ham sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())
output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_results_with_similarity.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Ham sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")

# Normalleştirilmiş sonuçları DataFrame'e çevir ve ayrı bir Excel'e kaydet
results_df_normalized = pd.DataFrame(result_list_normalized)
print("\nNormalleştirilmiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_normalized.head())
output_path_normalized = "/content/drive/MyDrive/Colab/result_list_normalized.xlsx"
results_df_normalized.to_excel(output_path_normalized, index=False)
print(f"Normalleştirilmiş sonuçlar Excel dosyasına kaydedildi: {output_path_normalized}")

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd
import re

# Ground truth okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"
if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Listeler
results_list_without_filters = []
result_list_normalized = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# Normalizasyon fonksiyonu
def normalize_text(text):
    text = text.lower()  # Büyük-küçük harf duyarlılığını kaldır
    text = text.replace(" ", "")  # Boşlukları kaldır
    # Belirtilen özel karakterleri temizle
    for char in ['*', "'", '"', '@','?', ';', '>', '<', '_', '-','(', ')','%', '&', '[',']']:
        text = text.replace(char, '')
    return text
# Benzerlik hesaplama
def calculate_similarity(ground_truth, detected):
    ground_truth_normalized = normalize_text(ground_truth)
    detected_normalized = normalize_text(detected)
    return (1 - distance(ground_truth_normalized, detected_normalized) /
            max(len(ground_truth_normalized), len(detected_normalized))) * 100

# Filtreleme fonksiyonu (confidence ve similarity hibrit)
def filter_detections(results, ground_truth, min_confidence=0.3, min_similarity=80):
    filtered_results = []
    gt_normalized = normalize_text(ground_truth)
    for (bbox, text, confidence) in results:
        similarity = calculate_similarity(ground_truth, text)
        # Confidence çok düşük değilse VEYA similarity yüksekse tut
        if (confidence >= min_confidence) or (similarity >= min_similarity):
            filtered_results.append((bbox, text, confidence))
    return filtered_results

# İşleme
for i, folder_path in enumerate(folder_paths, start=1):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # OCR işlemi
            results = reader.readtext(image_rgb, detail=1)
            detected_texts_raw = [result[1] for result in results]

            if not detected_texts_raw:
                print(f"No text detected for {image_name}.")
                detected_texts_raw = ["NO DETECTION"]

            # Ground truth kontrolü ve manuel giriş
            ground_truth = ground_truth_dict.get(image_name, "NA")
            if ground_truth == "NA":
                ground_truth = input(f"Database{i} - Gerçek Plaka Bilgisini Girin ({image_name}): ").strip()
                ground_truth_dict[image_name] = ground_truth

            # Filtreleme
            filtered_results = filter_detections(results, ground_truth, min_confidence=0.3, min_similarity=80)
            detected_texts_normalized = [normalize_text(result[1]) for result in filtered_results] if filtered_results else ["NO DETECTION"]

            # Bounding box çizimi
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            # Benzerlik hesaplama
            similarity_scores = [calculate_similarity(ground_truth, text) for text in detected_texts_normalized]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # Sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_raw,
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity
            })
            result_list_normalized.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_normalized,
                "Confidence Scores": [result[2] for result in filtered_results] if filtered_results else [],
                "Max Similarity (%)": max_similarity
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            error_entry = {
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Confidence Scores": [],
                "Max Similarity (%)": 0
            }
            results_list_without_filters.append(error_entry)
            result_list_normalized.append(error_entry)

# Çıktılar
results_df_without_filters = pd.DataFrame(results_list_without_filters)
results_df_without_filters.to_excel("/content/drive/MyDrive/Colab/OCR_results_with_similarity.xlsx", index=False)
print(f"Ham sonuçlar kaydedildi.")

results_df_normalized = pd.DataFrame(result_list_normalized)
results_df_normalized.to_excel("/content/drive/MyDrive/Colab/result_list_normalized.xlsx", index=False)
print(f"Normalleştirilmiş sonuçlar kaydedildi.")

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd
import re

# Ground truth okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"
if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Listeler
results_list_without_filters = []
result_list_normalized = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# Normalizasyon fonksiyonu
def normalize_text(text):
    text = text.lower().replace(" ", "")
    for char in ['*', "'", '"', '@','?', ';', '>', '<', '_', '-','(', ')','%', '&', '[',']']:
        text = text.replace(char, '')
    return text

# OCR hata düzeltmesi
def correct_ocr_text(detected, ground_truth):
    detected_normalized = normalize_text(detected)
    ground_truth_normalized = normalize_text(ground_truth)
    corrections = {'i': '1', 'l': '1', 'o': '0', 's': '5', 'b': '8', 'z': '2'}
    corrected = list(detected_normalized)

    for i, (det_char, gt_char) in enumerate(zip(detected_normalized, ground_truth_normalized)):
        if det_char != gt_char and det_char in corrections and corrections[det_char] == gt_char:
            corrected[i] = corrections[det_char]

    return ''.join(corrected)

# Benzerlik hesaplama
def calculate_similarity(ground_truth, detected):
    ground_truth_normalized = normalize_text(ground_truth)
    detected_normalized = normalize_text(detected)
    return (1 - distance(ground_truth_normalized, detected_normalized) /
            max(len(ground_truth_normalized), len(detected_normalized))) * 100

# Plaka bölgesini tespit et (plaka yoksa orijinal görüntüyü döndür)
def detect_plate_region(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.medianBlur(gray, 3)
    edged = cv2.Canny(blurred, 50, 150)
    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    plate_candidates = []
    for contour in contours:
        peri = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
        if len(approx) == 4:
            x, y, w, h = cv2.boundingRect(approx)
            aspect_ratio = w / float(h)
            if 1.5 < aspect_ratio < 5 and w > 80 and h > 5:
                plate_candidates.append((x, y, w, h))

    if plate_candidates:
        x, y, w, h = max(plate_candidates, key=lambda r: r[2] * r[3])
        return image[y:y+h, x:x+w]
    print("Plaka bölgesi tespit edilemedi, orijinal görüntü kullanılacak.")
    return image

# Görüntü ön işleme (bulanıklığı azalt)
def preprocess_image(image_path):
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Görüntü yüklenemedi: {image_path}")

    plate_region = detect_plate_region(image)

    # Beyaz dengesi (isteğe bağlı)
    try:
        lab = cv2.cvtColor(plate_region, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        avg_a, avg_b = np.mean(a), np.mean(b)
        a, b = a - avg_a + 128, b - avg_b + 128
        a, b = a.astype(l.dtype), b.astype(l.dtype)
        balanced = cv2.merge((l, a, b))
        plate_region = cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)
    except Exception as e:
        print(f"Beyaz dengesi hatası: {e}. Orijinal bölge kullanılıyor.")

    # Hafif bulanıklaştırma ve keskinleştirme
    plate_region = cv2.medianBlur(plate_region, 3)
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # Daha hafif keskinleştirme
    plate_region = cv2.filter2D(plate_region, -1, kernel)

    # Kontrast artırma
    lab = cv2.cvtColor(plate_region, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))  # Daha az agresif CLAHE
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

# Metinleri birleştir
def merge_detections(results, max_x_gap=80, max_y_gap=5):
    if not results:
        return [([0, 0, 0, 0], "NO DETECTION", 0.0)]

    sorted_results = sorted(results, key=lambda x: x[0][0][0])
    merged_groups = []
    current_group = []

    for (bbox, text, confidence) in sorted_results:
        x_start = int(bbox[0][0])
        y_start = int(bbox[0][1])
        x_end = int(bbox[1][0])

        if not current_group:
            current_group = [(bbox, text, confidence)]
        else:
            last_bbox, _, _ = current_group[-1]
            last_x_end = int(last_bbox[1][0])
            last_y = int(last_bbox[0][1])

            if (x_start - last_x_end <= max_x_gap) and (abs(y_start - last_y) <= max_y_gap):
                current_group.append((bbox, text, confidence))
            else:
                merged_groups.append(current_group)
                current_group = [(bbox, text, confidence)]

    if current_group:
        merged_groups.append(current_group)

    merged_results = []
    for group in merged_groups:
        merged_text = " ".join([item[1] for item in group])
        merged_confidence = sum([item[2] for item in group]) / len(group)
        merged_bbox = group[0][0] if group else [0, 0, 0, 0]
        merged_results.append((merged_bbox, merged_text, merged_confidence))

    return merged_results

# Filtreleme
def filter_detections(results, ground_truth, min_confidence=0.3, min_similarity=80):
    filtered_results = []
    gt_normalized = normalize_text(ground_truth)
    for (bbox, text, confidence) in results:
        corrected_text = correct_ocr_text(text, ground_truth)
        similarity = calculate_similarity(ground_truth, corrected_text)
        normalized_text = normalize_text(corrected_text)
        has_letters = any(c.isalpha() for c in normalized_text)
        has_digits = any(c.isdigit() for c in normalized_text)
        length_ok = 6 <= len(normalized_text) <= 10
        if (length_ok and has_letters and has_digits) or (confidence >= min_confidence and similarity >= min_similarity):
            filtered_results.append((bbox, corrected_text, confidence))
    if not filtered_results and results:
        best_result = max(results, key=lambda x: calculate_similarity(ground_truth, correct_ocr_text(x[1], ground_truth)))
        filtered_results.append((best_result[0], correct_ocr_text(best_result[1], ground_truth), best_result[2]))
    return filtered_results

# İşleme
for i, folder_path in enumerate(folder_paths, start=1):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Ön işleme ile OCR
            processed_image = preprocess_image(image_path)
            results = reader.readtext(processed_image, detail=1, contrast_ths=0.1)  # Bulanık görüntüler için kontrast ayarı
            detected_texts_raw = [result[1] for result in results]

            # Eğer OCR başarısızsa ham görüntüyle tekrar dene
            if not detected_texts_raw:
                print(f"No text detected in processed image for {image_name}. Trying raw image...")
                raw_image = cv2.imread(image_path)
                results = reader.readtext(raw_image, detail=1, contrast_ths=0.1)
                detected_texts_raw = [result[1] for result in results]
                processed_image = raw_image  # Görselleştirme için ham görüntüyü kullan

            if not detected_texts_raw:
                print(f"No text detected in raw image either for {image_name}. Possible non-plate image or excessive blur.")

            # Ground truth kontrolü ve manuel giriş
            ground_truth = ground_truth_dict.get(image_name, "NA")
            if ground_truth == "NA":
                ground_truth = input(f"Database{i} - Gerçek Plaka Bilgisini Girin ({image_name}): ").strip()
                ground_truth_dict[image_name] = ground_truth

            # Metinleri birleştir
            merged_results = merge_detections(results)
            detected_texts_merged = [result[1] for result in merged_results]

            # Filtreleme
            filtered_results = filter_detections(merged_results, ground_truth)
            detected_texts_normalized = [normalize_text(result[1]) for result in filtered_results]

            # Görselleştirme
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                if bbox and bbox != [0, 0, 0, 0]:
                    top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                    cv2.rectangle(processed_image, top_left, bottom_right, (255, 0, 0), 2)
                    cv2.putText(processed_image, text, (top_left[0], top_left[1] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            plt.imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - {image_name}")
            plt.show()

            # Benzerlik hesaplama
            similarity_scores = [calculate_similarity(ground_truth, text) for text in detected_texts_normalized]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")
            print(f"Merged Text: {detected_texts_merged}")

            # Sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_raw if detected_texts_raw else ["NO DETECTION"],
                "Confidence Scores": [result[2] for result in results] if results else [0.0],
                "Max Similarity (%)": max_similarity
            })
            result_list_normalized.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts_normalized,
                "Confidence Scores": [result[2] for result in filtered_results] if filtered_results else [0.0],
                "Max Similarity (%)": max_similarity
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            error_entry = {
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Confidence Scores": [0.0],
                "Max Similarity (%)": 0
            }
            results_list_without_filters.append(error_entry)
            result_list_normalized.append(error_entry)

# Çıktılar
results_df_without_filters = pd.DataFrame(results_list_without_filters)
results_df_without_filters.to_excel("/content/drive/MyDrive/Colab/OCR_results_with_similarity.xlsx", index=False)
print(f"Ham sonuçlar kaydedildi.")

results_df_normalized = pd.DataFrame(result_list_normalized)
results_df_normalized.to_excel("/content/drive/MyDrive/Colab/result_list_normalized.xlsx", index=False)
print(f"Normalleştirilmiş sonuçlar kaydedildi.")

































import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd

# Daha önce kaydedilen Excel dosyasından ground truth bilgilerini okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Tüm sonuçları saklamak için bir liste
results_list_without_filters = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# Fonksiyon: Beyaz dengesi
def white_balance(image):
    if image is None:
        raise ValueError("Girdi görüntüsü boş. Lütfen doğru bir yol girin.")

    try:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)

        # Kanalların boyutlarını kontrol et
        if l.shape != a.shape or l.shape != b.shape:
            raise ValueError("L, A ve B kanallarının boyutları eşleşmiyor.")

        avg_a = np.mean(a)
        avg_b = np.mean(b)
        a = a - avg_a + 128
        b = b - avg_b + 128

        # Veri tipi düzeltme
        a = a.astype(l.dtype)
        b = b.astype(l.dtype)

        balanced = cv2.merge((l, a, b))
        return cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)
    except Exception as e:
        raise ValueError(f"White balance sırasında hata oluştu: {e}")

# Fonksiyon: Gürültü azaltma
def denoise_image(image_rgb):
    return cv2.GaussianBlur(image_rgb, (5, 5), 0)

# Fonksiyon: Kontrast artırma
def enhance_contrast(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

# Fonksiyon: Görüntü işleme
def preprocess_image(image_path):
    image = cv2.imread(image_path)

    if image is None:
        raise ValueError(f"Görüntü yüklenemedi: {image_path}")

    try:
        image = white_balance(image)
    except ValueError as e:
        print(f"Beyaz dengesi hatası: {e}. İşlem atlanıyor.")
        raise e

    image = denoise_image(image)
    image = enhance_contrast(image)
    return image

# Her veri seti için işlemler
for i, folder_path in enumerate(folder_paths, start=1):
    # Her klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        # Görüntü yolu
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Görüntüyü işleme
            processed_image = preprocess_image(image_path)

            # OCR işlemi
            results = reader.readtext(processed_image, detail=1)
            detected_texts = [result[1] for result in results]

            if not detected_texts:
                print(f"No text detected for {image_name}. Please provide ground truth manually.")
                detected_texts = ["NO DETECTION"]

            # Ground Truth bilgisi kontrolü
            ground_truth = ground_truth_dict.get(image_name, "NA")  # Daha önce kayıtlıysa al, yoksa "NA" kullan
            if ground_truth == "NA":  # Eğer kayıtlı değilse kullanıcıdan iste
                ground_truth = input(f"Database{i} - Gerçek Plaka Bilgisini Girin ({image_name}): ").strip()
                ground_truth_dict[image_name] = ground_truth

            # OCR sonuçlarını yazdır
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")

            # Filtrelenmemiş sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts,
                "Confidence Scores": [result[2] for result in results] if results else []
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Confidence Scores": []
            })

# Sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)

# DataFrame'i baştan görselleştir
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())  # İlk 5 kaydı göster

output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Filtrelenmemiş sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd

# Daha önce kaydedilen Excel dosyasından ground truth bilgilerini okuma
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Tüm sonuçları saklamak için bir liste
results_list_without_filters = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# BURADA YENİ EKLENEN BİR KOD VAR !!!
# Görüntü ön işleme fonksiyonu ekleme
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# Benzerlik oranı hesaplama fonksiyonu
def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Her veri seti için işlemler
for i, folder_path in enumerate(folder_paths, start=1):
    # Her klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        # Görüntü yolu
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Görüntüyü oku ve RGB formatına çevir
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Görüntüyü ön işlemden geçir
            image_processed = preprocess_image(image)

            # OCR işlemi
            results = reader.readtext(image_processed, detail=1)
            detected_texts = [result[1] for result in results]

            if not detected_texts:
                print(f"No text detected for {image_name}.")
                detected_texts = ["NO DETECTION"]

            # OCR sonuçlarını yazdır ve bounding box çiz
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            # Bounding box'lı görüntüyü göster
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            # Ground Truth bilgisi kontrolü
            ground_truth = ground_truth_dict.get(image_name, "NA")  # Daha önce kayıtlıysa al, yoksa "NA" kullan
            if ground_truth == "NA":
                print(f"Ground truth bilgisi bulunamadı, lütfen manuel giriş yapın: {image_name}")
                continue

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Metinleri normalizasyon (büyük harf ve boşluk temizleme)
            ground_truth = ground_truth.upper().strip()
            detected_texts = [dt.upper().strip() for dt in detected_texts]

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Anlamsız tespitleri filtreleme
            detected_texts = [dt for dt in detected_texts if dt != "NO DETECTION" and dt.strip()]

            # Benzerlik oranını hesapla
            similarity_scores = [
                calculate_similarity(ground_truth, detected_text)
                for detected_text in detected_texts
            ]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Max length ve en yüksek güven skorlu metni ekleme
            max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))
            if results:
                max_confidence_idx = np.argmax([result[2] for result in results])
                best_detected_text = results[max_confidence_idx][1]
            else:
                best_detected_text = "NO DETECTION"

            # Filtrelenmemiş sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts,
                "Best Detected Text": best_detected_text,
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity,
                "Max Length": max_length
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Best Detected Text": "ERROR",
                "Confidence Scores": [],
                "Max Similarity (%)": 0,
                "Max Length": 0
            })

# Sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)

# DataFrame'i baştan görselleştir
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())  # İlk 5 kaydı göster

output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_results_with_similarity.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")



"""Debug kısmı geldi"""



image_path = "/content/drive/MyDrive/Colab/foggy/Cars21.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

# Ground truth bilgisini manuel olarak girin veya bir dosyadan okuyun
ground_truth = "1RQ"  # Örnek bir ground truth değeri
# ground_truth = ground_truth_dict.get(image_name) # Eğer bir ground truth sözlüğünüz varsa

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""2. deneme"""

image_path = "/content/drive/MyDrive/Colab/foggy/Cars161.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

ground_truth = "M666 YOB"

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""3.DENEME

"""

image_path = "/content/drive/MyDrive/Colab/foggy/Cars204.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

ground_truth = "N BYOND"

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""4. DENEME

"""

image_path = "/content/drive/MyDrive/Colab/foggy/Cars235.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

ground_truth = "GJ03JL0126"

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""Deneme 5

"""

image_path = "/content/drive/MyDrive/Colab/foggy/Cars310.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

ground_truth = "4GET OIL"

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""DENEME 6

"""

image_path = "/content/drive/MyDrive/Colab/foggy/Cars340.jpg"
print("Seçilen fotoğraf:", image_path)

import easyocr

# EasyOCR reader nesnesini oluştur
reader = easyocr.Reader(['tr'])

# Fotoğrafı oku ve detected text'leri al
results = reader.readtext(image_path)

# Tespit edilen metinleri yazdır
print("Tespit edilen metinler:")
for (bbox, text, prob) in results:
    print(f"Metin: {text}, Güven: {prob:.2f}")

detected_texts = [text for (bbox, text, prob) in results]
print("Detected texts listesi:", detected_texts)

ground_truth = "VX54 FVL"

from Levenshtein import distance

def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Benzerlik oranını hesaplama
similarity_scores = [calculate_similarity(ground_truth, detected_text) for detected_text in detected_texts]
max_similarity = max(similarity_scores) if similarity_scores else 0

# Maksimum uzunluk hesaplama
max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))

print(f"Ground Truth: {ground_truth}")
print(f"Detected Texts: {detected_texts}")
print(f"Max Similarity: {max_similarity:.2f}%")
print(f"Max Length: {max_length}")

"""Debug bitti

"""

import pandas as pd

# Excel dosyasını oku
df = pd.read_excel("/content/drive/MyDrive/Colab/OCR_truthtable_similarity.xlsx")
ground_truth = df[df["Image Name"] == "Cars21.jpg"]["Ground Truth"].values[0]
print("Ground Truth:", ground_truth)

import easyocr
import cv2
import matplotlib.pyplot as plt

# Görüntü yolu
image_path = "/content/drive/MyDrive/Colab/foggy/Cars21.jpg"  # Örnek bir görsel yolu

# EasyOCR başlatma
reader = easyocr.Reader(['en'], gpu=True)

# Görüntüyü okuma ve OCR işlemi
image = cv2.imread(image_path)
results = reader.readtext(image)

# Tespit edilen metinler
detected_texts = [result[1] for result in results]

print("Tespit edilen metinler:", detected_texts)

# Ground truth bilgisini manuel olarak girin veya bir dosyadan okuyun
ground_truth = "1RQ"  # Örnek bir ground truth değeri
# ground_truth = ground_truth_dict.get(image_name) # Eğer bir ground truth sözlüğünüz varsa



def white_balance(image):
    if image is None:
        raise ValueError("No input img. Check the image path.")

    # LAB renk uzayına dönüştürme
    try:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        print("LAB Shape:", lab.shape)
    except Exception as e:
        raise ValueError(f"LAB dönüşümünde hata: {e}")

    # Kanalları ayırma
    try:
        l, a, b = cv2.split(lab)
        print("L Kanalı:", l.shape)
        print("A Kanalı:", a.shape)
        print("B Kanalı:", b.shape)
    except Exception as e:
        raise ValueError(f"Kanalları ayırırken hata: {e}")

    # Ortalama hesaplama
    avg_a = np.mean(a)
    avg_b = np.mean(b)
    print("Ortalama A:", avg_a)
    print("Ortalama B:", avg_b)

    # Normalizasyon
    a = a - avg_a + 128 #nötr değeri
    b = b - avg_b + 128

    # Veri tipi düzeltme
    a = a.astype(l.dtype)
    b = b.astype(l.dtype)

    # Kanalları birleştir ve BGR'ye geri dönüştür
    balanced = cv2.merge((l, a, b))
    return cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)

"""LAB Renk Uzayı Nedir?
L Kanalı: Işıklandırma bilgisini (parlaklık) içerir.
A Kanalı: Yeşil-kırmızı renk bileşenlerini temsil eder.
B Kanalı: Mavi-sarı renk bileşenlerini temsil eder.
Neden LAB Renk Uzayı?
LAB renk uzayında renk bilgisi (A ve B kanalları) ile parlaklık bilgisi (L kanalı) ayrılmıştır.
Bu, renk ayarlarının parlaklık bilgisine dokunulmadan yapılmasına olanak tanır.
"""

def denoise_image(image_rgb):
    # Gaussian Blur ile gürültü azaltma
    blurred = cv2.GaussianBlur(image_rgb, (5, 5), 0)
    return blurred

def normalize_text(text):
       text = text.upper()  # Büyük harfe çevir
       text = ''.join(filter(str.isalnum, text))  # Alfanümerik olmayan karakterleri kaldır
       return text

# Plaka boyutlarıyla uyumlu bounding box'ları kontrol et
def is_plate_shape(bbox, min_aspect_ratio=2, max_aspect_ratio=5, min_area=1000, max_area=10000):
    top_left = bbox[0]
    bottom_right = bbox[2]  # bottom_right, köşe bilgilerinin 3. elemanıdır.

    width = bottom_right[0] - top_left[0]
    height = bottom_right[1] - top_left[1]
    area = width * height
    aspect_ratio = width / height if height > 0 else 0

    if (
        min_aspect_ratio <= aspect_ratio <= max_aspect_ratio and
        min_area <= area <= max_area
    ):
        return True
    return False


def enhance_contrast(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)


def preprocess_image(image_path):
    img = cv2.imread(image_path)

    # Foggy efekti azaltma - Gaussian Blur
    img = denoise_image(img)

    # Beyaz dengesi ayarı
    img = white_balance(img)

    # CLAHE ile kontrast artırma
    img = enhance_contrast(img)

    # Gri tonlamaya çevirme
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # İşlenmiş gri görüntüyü döndür
    return gray

'''
# Grayscale sonrası siyah-beyaz dönüşüm
def convert_to_binary(gray, threshold=210):
    _, binary_image = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)
    return binary_image '''

# Görüntüyü ön işle
preprocessed_image = preprocess_image(image_path)
preprocessed_image = denoise_image(preprocessed_image)  # Gürültü giderme


# Bounding box'ları filtrele
filtered_results = [
    result for result in results
    if is_plate_shape(result[0])  # result[0] bounding box koordinatlarını içerir
]

# OCR sonuçlarını yazdır
detected_texts = [normalize_text(result[1]) for result in filtered_results]
print("Detected Texts:", detected_texts)


# Görselleştirme
plt.imshow(preprocessed_image, cmap='gray')
plt.axis('off')
plt.title("OCR Sonucu")
plt.show()

"""CLAHE (Contrast Limited Adaptive Histogram Equalization): Görüntüdeki kontrastı artırmak için kullanılan bir yöntemdir.

Adaptif Histogram Eşitleme (AHE): Görüntüyü küçük parçalara (tile) böler ve her parça için ayrı bir histogram eşitleme uygular.
Kontrast Sınırlandırma (CLAHE): Fazla doygunlaşmayı önlemek için histogramdaki aşırı yüksek değerleri sınırlar.
"""

from google.colab.patches import cv2_imshow

# Beyaz dengesi uygulama
try:
    white_balanced_image = white_balance(image)
    print("Beyaz dengesi başarıyla uygulandı.")
except ValueError as ve:
    print(f"Hata: {ve}")
except Exception as e:
    print(f"Beklenmeyen bir hata oluştu: {e}")

# Sonucu göster
cv2_imshow(white_balanced_image)

# OCR işlemi uygulama
results = reader.readtext(white_balanced_image, detail=1)

# Bounding box çizimi
for (bbox, text, confidence) in results:
    print(f"Bulunan Metin: {text} | Güven: {confidence}")

    # Bounding box koordinatlarını al
    (top_left, top_right, bottom_right, bottom_left) = bbox
    top_left = tuple(map(int, top_left))
    bottom_right = tuple(map(int, bottom_right))

    # Bounding box çizimi
    cv2.rectangle(white_balanced_image, top_left, bottom_right, (0, 255, 0), 2)

    # Metin yazdırma
    cv2.putText(white_balanced_image, text, (top_left[0], top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

# Sonucu göster
cv2_imshow(white_balanced_image)

import cv2
import easyocr
import pandas as pd
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from difflib import SequenceMatcher
from Levenshtein import distance
import numpy as np

# Excel dosyasını oku
df = pd.read_excel("/content/drive/MyDrive/Colab/OCR_truthtable_similarity.xlsx")
image_name = "Cars21.jpg"
ground_truth = df[df["Image Name"] == image_name]["Ground Truth"].values[0]
print("Ground Truth:", ground_truth)  # Çıktı: 1RQ

# Görüntü yolu
image_path = "/content/drive/MyDrive/Colab/foggy/Cars21.jpg"

def white_balance(image):
    if image is None:
        raise ValueError("No input img. Check the image path.")
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    avg_a = np.mean(a)
    avg_b = np.mean(b)
    a = a - avg_a + 128
    b = b - avg_b + 128
    a = a.astype(l.dtype)
    b = b.astype(l.dtype)
    balanced = cv2.merge((l, a, b))
    return cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)

def denoise_image(image_rgb):
    return cv2.GaussianBlur(image_rgb, (5, 5), 0)

def enhance_contrast(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = denoise_image(img)
    img = white_balance(img)
    img = enhance_contrast(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Eşikleme ekleyerek metni belirginleştir
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary

def normalize_text(text):
    text = text.upper()
    text = ''.join(filter(str.isalnum, text))
    return text

def is_plate_shape(bbox, min_aspect_ratio=2, max_aspect_ratio=5, min_area=100, max_area=15000):
    top_left = bbox[0]
    bottom_right = bbox[2]
    width = bottom_right[0] - top_left[0]
    height = bottom_right[1] - top_left[1]
    area = width * height
    aspect_ratio = width / height if height > 0 else 0
    return (min_aspect_ratio <= aspect_ratio <= max_aspect_ratio and min_area <= area <= max_area)

# EasyOCR başlatma
reader = easyocr.Reader(['en'], gpu=True)

# Görüntüyü ön işle
image = cv2.imread(image_path)
preprocessed_image = preprocess_image(image_path)

# OCR işlemi
results = reader.readtext(preprocessed_image, detail=1)

# Bounding box'ları filtrele
filtered_results = [result for result in results if is_plate_shape(result[0])]

# Tespit edilen metinleri normalize et
detected_texts = [normalize_text(result[1]) for result in filtered_results]
print("Detected Texts:", detected_texts)

normalized_ground_truth = normalize_text(ground_truth)
normalized_detected = detected_texts  # Zaten normalize edildi
print("Normalized Ground Truth:", normalized_ground_truth)
print("Normalized Detected Texts:", normalized_detected)

def calculate_similarity(ground_truth, detected):
    return SequenceMatcher(None, ground_truth, detected).ratio() * 100

def calculate_and_display_metrics(ground_truth, detected):
    lev_distance = distance(ground_truth, detected)
    max_length = max(len(ground_truth), len(detected))
    levenshtein_accuracy = (1 - lev_distance / max_length) * 100 if max_length > 0 else 0
    similarity = SequenceMatcher(None, ground_truth, detected).ratio() * 100
    truth_table_ratio = len(ground_truth) / len(detected) if len(detected) > 0 else 0
    detected_ratio = len(detected) / len(ground_truth) if len(ground_truth) > 0 else 0
    print(f"Levenshtein Accuracy: {levenshtein_accuracy:.2f}%")
    print(f"Similarity: {similarity:.2f}%")
    print(f"Truth Table / Detected: {truth_table_ratio:.2f}")
    print(f"Detected / Truth Table: {detected_ratio:.2f}")

# Hesaplama
if normalized_detected:
    for detected in normalized_detected:
        similarity = calculate_similarity(normalized_ground_truth, detected)
        print(f"Benzerlik Oranı: {similarity:.2f}%")
        calculate_and_display_metrics(normalized_ground_truth, detected)
else:
    print("No text detected.")

for (bbox, text, confidence) in filtered_results:
    top_left = tuple(map(int, bbox[0]))
    bottom_right = tuple(map(int, bbox[2]))
    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
    cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

cv2_imshow(image)

import cv2
import easyocr
import pandas as pd
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from difflib import SequenceMatcher
from Levenshtein import distance
import numpy as np

# Excel dosyasını oku
df = pd.read_excel("/content/drive/MyDrive/Colab/OCR_truthtable_similarity.xlsx")
image_name = "Cars21.jpg"
ground_truth = df[df["Image Name"] == image_name]["Ground Truth"].values[0]
print("Ground Truth:", ground_truth)

# Görüntü yolu
image_path = "/content/drive/MyDrive/Colab/foggy/Cars21.jpg"
image = cv2.imread(image_path)

# Yardımcı fonksiyonlar
def white_balance(image):
    if image is None:
        raise ValueError("No input img. Check the image path.")
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    avg_a = np.mean(a)
    avg_b = np.mean(b)
    a = a - avg_a + 128
    b = b - avg_b + 128
    a = a.astype(l.dtype)
    b = b.astype(l.dtype)
    balanced = cv2.merge((l, a, b))
    return cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)

def denoise_image(image_rgb):
    return cv2.GaussianBlur(image_rgb, (5, 5), 0)

def enhance_contrast(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = denoise_image(img)
    img = white_balance(img)
    img = enhance_contrast(img)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary

def normalize_text(text):
    text = text.upper()
    text = ''.join(filter(str.isalnum, text))
    return text

def is_plate_shape(bbox, min_aspect_ratio=1, max_aspect_ratio=10, min_area=100, max_area=50000):
    top_left = bbox[0]
    bottom_right = bbox[2]
    width = bottom_right[0] - top_left[0]
    height = bottom_right[1] - top_left[1]
    area = width * height
    aspect_ratio = width / height if height > 0 else 0
    return (min_aspect_ratio <= aspect_ratio <= max_aspect_ratio and min_area <= area <= max_area)

# EasyOCR başlatma
reader = easyocr.Reader(['en'], gpu=True)

# Görüntüyü ön işle
preprocessed_image = preprocess_image(image_path)

# OCR işlemi
results = reader.readtext(preprocessed_image, detail=1)

# Bounding box'ları filtrele
filtered_results = [result for result in results if is_plate_shape(result[0])]

# Tespit edilen metinleri normalize et
detected_texts = [normalize_text(result[1]) for result in filtered_results]
print("Detected Texts:", detected_texts)

# Metinleri normalize et
normalized_ground_truth = normalize_text(ground_truth)
normalized_detected = detected_texts
print("Normalized Ground Truth:", normalized_ground_truth)
print("Normalized Detected Texts:", normalized_detected)

# Benzerlik ve doğruluk hesaplama
def calculate_similarity(ground_truth, detected):
    return SequenceMatcher(None, ground_truth, detected).ratio() * 100

def calculate_and_display_metrics(ground_truth, detected):
    lev_distance = distance(ground_truth, detected)
    max_length = max(len(ground_truth), len(detected))
    levenshtein_accuracy = (1 - lev_distance / max_length) * 100 if max_length > 0 else 0
    similarity = SequenceMatcher(None, ground_truth, detected).ratio() * 100
    truth_table_ratio = len(ground_truth) / len(detected) if len(detected) > 0 else 0
    detected_ratio = len(detected) / len(ground_truth) if len(ground_truth) > 0 else 0
    print(f"Levenshtein Accuracy: {levenshtein_accuracy:.2f}%")
    print(f"Similarity: {similarity:.2f}%")
    print(f"Truth Table / Detected: {truth_table_ratio:.2f}")
    print(f"Detected / Truth Table: {detected_ratio:.2f}")

if normalized_detected:
    for detected in normalized_detected:
        similarity = calculate_similarity(normalized_ground_truth, detected)
        print(f"Benzerlik Oranı: {similarity:.2f}%")
        calculate_and_display_metrics(normalized_ground_truth, detected)
else:
    print("No text detected.")

# Görselleştirme
for (bbox, text, confidence) in filtered_results:
    top_left = tuple(map(int, bbox[0]))
    bottom_right = tuple(map(int, bbox[2]))
    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
    cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

cv2_imshow(image)

print("Ham OCR Sonuçları:", results)

from google.colab.patches import cv2_imshow
import cv2

# Görüntüyü yükle
image = cv2.imread("/content/drive/MyDrive/Colab/foggy/Cars21.jpg")

# Görüntüyü göster
cv2_imshow(image)

results = reader.readtext(image, detail=1)
detected_texts = [result[1] for result in results]
print("Filtresiz OCR Sonuçları:", detected_texts)

results = reader.readtext(image, detail=0)
print("Detail=0 OCR Sonuçları:", results)

results = reader.readtext(image, min_size=10, paragraph=True)
print("Min_size=10, paragraph=True Sonuçları:", [result[1] for result in results])

from google.colab.patches import cv2_imshow
import cv2
import easyocr

# Görüntüyü yükle (dosya yolunuza göre güncelleyin)
image = cv2.imread("/content/drive/MyDrive/Colab/foggy/Cars21.jpg")  # Dosya yolunu kendi görüntünüze göre ayarlayın

# Gri tonlamaya çevir
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Histogram eşitleme
equalized = cv2.equalizeHist(gray)

# İşlenmiş görüntüyü göster
cv2_imshow(equalized)

# EasyOCR okuyucuyu başlat
reader = easyocr.Reader(['en'], gpu=True)

# OCR işlemi
results = reader.readtext(equalized)

# Tespit edilen metinleri yazdır
print("Sonuçlar:", [result[1] for result in results])

adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                cv2.THRESH_BINARY, 11, 2)
results = reader.readtext(adaptive)
print("Adaptif Eşikleme Sonuçları:", [result[1] for result in results])

from difflib import SequenceMatcher

def calculate_similarity(ground_truth, detected):
    return SequenceMatcher(None, ground_truth, detected).ratio() * 100

similarity = calculate_similarity(normalized_ground_truth, normalized_detected)
print(f"Benzerlik Oranı: {similarity:.2f}%")

# Doğruluk metriklerini hesaplayan ve yazdıran fonksiyon
def calculate_and_display_metrics(ground_truth, detected):
    from difflib import SequenceMatcher
    from Levenshtein import distance  # Eğer "Levenshtein" modülü yoksa yükleyin: pip install python-Levenshtein

    # Levenshtein Distance ile doğruluk hesaplama
    lev_distance = distance(ground_truth, detected)
    max_length = max(len(ground_truth), len(detected))
    levenshtein_accuracy = (1 - lev_distance / max_length) * 100 if max_length > 0 else 0

    # Benzerlik oranı
    similarity = SequenceMatcher(None, ground_truth, detected).ratio() * 100

    # Truth Table / Detected ve Detected / Truth Table oranları
    truth_table_ratio = len(ground_truth) / len(detected) if len(detected) > 0 else 0
    detected_ratio = len(detected) / len(ground_truth) if len(ground_truth) > 0 else 0

    # Sonuçların yazdırılması
    results = {
        "Truth Table / Detected": truth_table_ratio,
        "Detected / Truth Table": detected_ratio
    }
    for key, value in results.items():
        print(f"{key}: {value:.2f}")

# Kullanım: normalized_ground_truth ve normalized_detected tanımlı olmalıdır
calculate_and_display_metrics(normalized_ground_truth, normalized_detected)

"""WHITE BALANCE YAPILIP DOĞRULUK ORANI ARTTIRILDI. LAB KULLANILDI KONTRAST ARTTIRILDI. LEVENSHTEIN ILE DOĞRULUK HESAPLANDI."""

from google.colab import drive
import os
import pandas as pd

# Google Drive'ı bağla
drive.mount('/content/drive/')

# Veri seti klasör yollarını tanımlayın
folder_paths = [
    "/content/drive/MyDrive/Colab/foggy",
    "/content/drive/MyDrive/Colab/dortmund"
]

# Görüntüleri listeleme
for folder_path in folder_paths:
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Klasör: {folder_path}, Görüntü Sayısı: {len(image_files)}")

try:
    import torch
    import easyocr
    from Levenshtein import distance
except ImportError:
    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    !pip install easyocr
    !pip install python-Levenshtein

'''

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install easyocr
!pip install python-Levenshtein
'''

import easyocr
import numpy as np
import cv2
# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)

# Ground Truth yükleme
ground_truth_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"
if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground Truth bilgileri yüklendi.")
else:
    ground_truth_dict = {}

# Filtrelenmemiş OCR sonuçları
results_list_without_filters = []

for i, folder_path in enumerate(folder_paths, start=1):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    for image_name in image_files:
        image_path = os.path.join(folder_path, image_name)
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = reader.readtext(image_rgb, detail=1)
        detected_texts = [result[1] for result in results]

        # Ground Truth kontrolü
        ground_truth = ground_truth_dict.get(image_name, "NA")
        if ground_truth == "NA":
            ground_truth = input(f"{image_name} için Ground Truth girin: ")
            ground_truth_dict[image_name] = ground_truth

        # Sonuçları kaydet
        results_list_without_filters.append({
            "Image Name": image_name,
            "Ground Truth": ground_truth,
            "Detected Texts": detected_texts
        })

# Sonuçları kaydet
df_results_without_filters = pd.DataFrame(results_list_without_filters)
output_path = "/content/drive/MyDrive/Colab/OCR_results_without_filters.xlsx"
df_results_without_filters.to_excel(output_path, index=False)
print("Filtrelenmemiş OCR sonuçları kaydedildi.")

def white_balance(image):
    if image is None:
        raise ValueError("Girdi görüntüsü boş. Lütfen doğru bir yol girin.")

    try:
        # LAB renk uzayına çevirme
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)

        # Kanal boyutlarının eşleştiğini doğrula
        if l.shape != a.shape or l.shape != b.shape:
            raise ValueError("L, A ve B kanallarının boyutları eşleşmiyor.")

        # Ortalama değerlerle normalize etme
        avg_a = np.mean(a)
        avg_b = np.mean(b)
        a = a - avg_a + 128
        b = b - avg_b + 128

        # Veri tipi dönüşümü
        a = a.astype(l.dtype)
        b = b.astype(l.dtype)

        # Kanalları birleştir
        balanced = cv2.merge((l, a, b))
        return cv2.cvtColor(balanced, cv2.COLOR_LAB2BGR)
    except Exception as e:
        raise ValueError(f"White balance sırasında hata oluştu: {e}")

def enhance_contrast(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)

    # Kanal boyutlarının eşleştiğini kontrol edin
    if cl.shape != a.shape or cl.shape != b.shape:
        raise ValueError("CLAHE uygulandıktan sonra kanal boyutları eşleşmiyor.")

    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)

def denoise_image(image):
    return cv2.GaussianBlur(image, (5, 5), 0)

import cv2
import easyocr
import pandas as pd
from google.colab.patches import cv2_imshow
from difflib import SequenceMatcher
from Levenshtein import distance
import numpy as np

# Excel dosyasını oku
df = pd.read_excel("/content/drive/MyDrive/Colab/OCR_truthtable_similarity.xlsx")
image_name = "Cars21.jpg"
ground_truth = df[df["Image Name"] == image_name]["Ground Truth"].values[0]
print("Ground Truth:", ground_truth)

# Görüntü yolu
image_path = "/content/drive/MyDrive/Colab/foggy/Cars21.jpg"
image = cv2.imread(image_path)

# Ön işleme fonksiyonu (basitleştirilmiş)
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.medianBlur(img, 5)  # Daha hafif bulanıklaştırma
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    return adaptive

# EasyOCR başlatma
reader = easyocr.Reader(['en'], gpu=True)

# Görüntüyü ön işle ve OCR yap
preprocessed_image = preprocess_image(image_path)
cv2_imshow(preprocessed_image)  # Ön işleme sonucunu kontrol et
results = reader.readtext(preprocessed_image, detail=1)

# Bounding box filtreleme (gevşetilmiş kriterler)
def is_plate_shape(bbox, min_aspect_ratio=1, max_aspect_ratio=10, min_area=50, max_area=50000):
    top_left = bbox[0]
    bottom_right = bbox[2]
    width = bottom_right[0] - top_left[0]
    height = bottom_right[1] - top_left[1]
    area = width * height
    aspect_ratio = width / height if height > 0 else 0
    return (min_aspect_ratio <= aspect_ratio <= max_aspect_ratio and min_area <= area <= max_area)

filtered_results = [result for result in results if is_plate_shape(result[0])]

# Tespit edilen metinleri normalize et
def normalize_text(text):
    text = text.upper()
    text = ''.join(filter(str.isalnum, text))
    return text

detected_texts = [normalize_text(result[1]) for result in filtered_results]
print("Detected Texts:", detected_texts)

# Normalizasyon ve metrik hesaplama
normalized_ground_truth = normalize_text(ground_truth)
normalized_detected = detected_texts
print("Normalized Ground Truth:", normalized_ground_truth)
print("Normalized Detected Texts:", normalized_detected)

def calculate_similarity(ground_truth, detected):
    return SequenceMatcher(None, ground_truth, detected).ratio() * 100

if normalized_detected:
    for detected in normalized_detected:
        similarity = calculate_similarity(normalized_ground_truth, detected)
        print(f"Benzerlik Oranı: {similarity:.2f}%")
else:
    print("No text detected.")

# Görselleştirme
for (bbox, text, confidence) in filtered_results:
    top_left = tuple(map(int, bbox[0]))
    bottom_right = tuple(map(int, bbox[2]))
    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
    cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
cv2_imshow(image)

from difflib import SequenceMatcher
from Levenshtein import distance

# Metrik fonksiyonları
def calculate_accuracy(ground_truth, detected):
    lev_distance = distance(ground_truth, detected)
    max_length = max(len(ground_truth), len(detected))
    return (1 - lev_distance / max_length) * 100 if max_length > 0 else 0

def calculate_similarity(ground_truth, detected):
    return SequenceMatcher(None, ground_truth, detected).ratio() * 100

# Karşılaştırma
for result in filtered_results:
    ground_truth = result["Ground Truth"]
    detected = ''.join(result["Detected Texts (Filtered)"])
    accuracy = calculate_accuracy(ground_truth, detected)
    similarity = calculate_similarity(ground_truth, detected)
    print(f"{result['Image Name']}: Accuracy={accuracy:.2f}%, Similarity={similarity:.2f}%")

from google.colab import drive
drive.mount('/content/drive/')
!ls /content/drive/MyDrive/Colab/dortmund/dortmund100

import os
import pandas as pd
import numpy as np
folder_path = [
    "/content/drive/MyDrive/Colab/dortmund/dortmund100"
]

folder_path = "/content/drive/MyDrive/Colab/dortmund/dortmund100"
# Klasördeki görüntüleri listele
image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
print(f"dortmund100 için Toplam Görüntü Sayısı: {len(image_files)}")

# İlk birkaç görüntüyü kontrol et
print("dortmund100 :")
print(image_files[:5])
!ls /content/drive/MyDrive/Colab/dortmund/dortmund100/

import os
import pandas as pd
import numpy as np

# Sadece dortmund100 klasörü için yol tanımla
folder_paths = [
    "/content/drive/MyDrive/Colab/dortmund/dortmund100"
]

for folder_path in folder_paths:
    print(f"Processing folder: {folder_path}")

    # Klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"Total images found: {len(image_files)}")

    # Dosyalardan numaraları çıkarma
    image_data = []
    for file_name in image_files:
        try:
            number = int(''.join(filter(str.isdigit, file_name)))
        except ValueError:
            number = None
        image_data.append({"File Name": file_name, "Original Number": number})

    # DataFrame oluştur ve işle
    df = pd.DataFrame(image_data).dropna(subset=["Original Number"])
    df["Original Number"] = df["Original Number"].astype(int)
    df = df.sort_values(by="Original Number").reset_index(drop=True)
    df["Mapped Number"] = np.linspace(1, len(df), len(df)).astype(int)

    # Her klasöre özel Excel dosyası kaydet
    output_path = os.path.join(folder_path, "image_mapped_list.xlsx")
    df.to_excel(output_path, index=False)
    print(f"Excel dosyası kaydedildi: {output_path}")

!pip install easyocr

!pip install python-Levenshtein

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd

# Ground truth dosyasını oku
ground_truth_path = "/content/drive/MyDrive/Colab/dortmund/dortmund_100_ground_truth.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Sonuçları saklayacak liste
results_list_without_filters = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)


# BURADA YENİ EKLENEN BİR KOD VAR !!!
# Görüntü ön işleme fonksiyonu ekleme
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# Benzerlik oranı hesaplama fonksiyonu
def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Her veri seti için işlemler
for i, folder_path in enumerate(folder_paths, start=1):
    # Her klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        # Görüntü yolu
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Görüntüyü oku ve RGB formatına çevir
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Görüntüyü ön işlemden geçir
            image_processed = preprocess_image(image)

            # OCR işlemi
            results = reader.readtext(image_processed, detail=1)
            detected_texts = [result[1] for result in results]

            if not detected_texts:
                print(f"No text detected for {image_name}.")
                detected_texts = ["NO DETECTION"]

            # OCR sonuçlarını yazdır ve bounding box çiz
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            # Bounding box'lı görüntüyü göster
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            # Ground Truth bilgisi kontrolü
            ground_truth = ground_truth_dict.get(image_name, "NA")  # Daha önce kayıtlıysa al, yoksa "NA" kullan
            if ground_truth == "NA":
                print(f"Ground truth bilgisi bulunamadı, lütfen manuel giriş yapın: {image_name}")
                continue

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Metinleri normalizasyon (büyük harf ve boşluk temizleme)
            ground_truth = ground_truth.upper().strip()
            detected_texts = [dt.upper().strip() for dt in detected_texts]

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Anlamsız tespitleri filtreleme
            detected_texts = [dt for dt in detected_texts if dt != "NO DETECTION" and dt.strip()]

            # Benzerlik oranını hesapla
            similarity_scores = [
                calculate_similarity(ground_truth, detected_text)
                for detected_text in detected_texts
            ]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Max length ve en yüksek güven skorlu metni ekleme
            max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))
            if results:
                max_confidence_idx = np.argmax([result[2] for result in results])
                best_detected_text = results[max_confidence_idx][1]
            else:
                best_detected_text = "NO DETECTION"

            # Filtrelenmemiş sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts,
                "Best Detected Text": best_detected_text,
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity,
                "Max Length": max_length
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Best Detected Text": "ERROR",
                "Confidence Scores": [],
                "Max Similarity (%)": 0,
                "Max Length": 0
            })

# Sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)

# DataFrame'i baştan görselleştir
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())  # İlk 5 kaydı göster

output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_dortmund_results_with_similarity.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")

import random
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance
import os
import numpy as np
import pandas as pd

# Ground truth dosyasını oku
ground_truth_path = "/content/drive/MyDrive/Colab/dortmund/dortmund_100_ground_truth.xlsx"

if os.path.exists(ground_truth_path):
    ground_truth_df = pd.read_excel(ground_truth_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Ground truth bilgileri Excel'den başarıyla yüklendi.")
else:
    print("Ground truth bilgileri yüklenemedi. Yeni bilgiler kaydedilecek.")
    ground_truth_dict = {}

# Sonuçları saklayacak liste
results_list_without_filters = []

# EasyOCR başlat
reader = easyocr.Reader(['en'], gpu=True)


# BURADA YENİ EKLENEN BİR KOD VAR !!!
# Görüntü ön işleme fonksiyonu ekleme
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# Benzerlik oranı hesaplama fonksiyonu
def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Her veri seti için işlemler
# folder_paths değişkeninin doğru olduğundan emin olun
folder_paths = [ #  This was the original folder_paths list definition
    "/content/drive/MyDrive/Colab/dortmund/dortmund100"
]
for i, folder_path in enumerate(folder_paths, start=1): # Using the original folder_paths
    # Her klasördeki görüntüleri listele
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Processing Database{i} - {folder_path}")
    for image_name in image_files:
        # Görüntü yolu
        image_path = os.path.join(folder_path, image_name)
        print(f"Processing Image: {image_name}")

        try:
            # Görüntüyü oku ve RGB formatına çevir
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Görüntüyü ön işlemden geçir
            image_processed = preprocess_image(image)

            # OCR işlemi
            results = reader.readtext(image_processed, detail=1)
            detected_texts = [result[1] for result in results]

            if not detected_texts:
                print(f"No text detected for {image_name}.")
                detected_texts = ["NO DETECTION"]

            # OCR sonuçlarını yazdır ve bounding box çiz
            for (bbox, text, confidence) in results:
                print(f"Detected Text: {text} | Confidence: {confidence}")
                top_left, bottom_right = tuple(map(int, bbox[0])), tuple(map(int, bbox[2]))
                cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)
                cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            # Bounding box'lı görüntüyü göster
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.title(f"Database{i} - Bounding Box: {image_name}")
            plt.show()

            # Ground Truth bilgisi kontrolü
            ground_truth = ground_truth_dict.get(image_name, "NA")  # Daha önce kayıtlıysa al, yoksa "NA" kullan
            if ground_truth == "NA":
                print(f"Ground truth bilgisi bulunamadı, lütfen manuel giriş yapın: {image_name}")
                continue

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Metinleri normalizasyon (büyük harf ve boşluk temizleme)
            ground_truth = ground_truth.upper().strip()
            detected_texts = [dt.upper().strip() for dt in detected_texts]

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Anlamsız tespitleri filtreleme
            detected_texts = [dt for dt in detected_texts if dt != "NO DETECTION" and dt.strip()]

            # Benzerlik oranını hesapla
            similarity_scores = [
                calculate_similarity(ground_truth, detected_text)
                for detected_text in detected_texts
            ]
            max_similarity = max(similarity_scores) if similarity_scores else 0
            print(f"Ground Truth: {ground_truth} | Max Similarity: {max_similarity:.2f}%")

            # BURADA YENİ EKLENEN BİR KOD VAR !!!
            # Max length ve en yüksek güven skorlu metni ekleme
            max_length = max(len(ground_truth), max([len(dt) for dt in detected_texts] or [0]))
            if results:
                max_confidence_idx = np.argmax([result[2] for result in results])
                best_detected_text = results[max_confidence_idx][1]
            else:
                best_detected_text = "NO DETECTION"

            # Filtrelenmemiş sonuçları kaydet
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": ground_truth,
                "Detected Texts": detected_texts,
                "Best Detected Text": best_detected_text,
                "Confidence Scores": [result[2] for result in results] if results else [],
                "Max Similarity (%)": max_similarity,
                "Max Length": max_length
            })

        except Exception as e:
            print(f"Error processing image {image_name}: {e}")
            results_list_without_filters.append({
                "Database": f"Database{i}",
                "Image Name": image_name,
                "Ground Truth": "ERROR",
                "Detected Texts": ["ERROR"],
                "Best Detected Text": "ERROR",
                "Confidence Scores": [],
                "Max Similarity (%)": 0,
                "Max Length": 0
            })

# Sonuçları DataFrame'e çevir ve Excel'e kaydet
results_df_without_filters = pd.DataFrame(results_list_without_filters)

# DataFrame'i baştan görselleştir
print("\nFiltrelenmemiş Sonuçlar (İlk 5 Kayıt):")
print(results_df_without_filters.head())  # İlk 5 kaydı göster

output_path_without_filters = "/content/drive/MyDrive/Colab/OCR_dortmund_results_with_similarity.xlsx"
results_df_without_filters.to_excel(output_path_without_filters, index=False)
print(f"Sonuçlar Excel dosyasına kaydedildi: {output_path_without_filters}")

import os
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
import easyocr
from Levenshtein import distance

# === AYARLAR ===
folder_path = "/content/drive/MyDrive/Colab/dortmund/dortmund100"
output_csv_path = "/content/drive/MyDrive/Colab/dortmund/ground_truth_generated.csv"
existing_gt_path = "/content/drive/MyDrive/Colab/dortmund/dortmund_100_ground_truth.xlsx"

# OCR Başlat
reader = easyocr.Reader(['en'], gpu=True)

# Mevcut Ground Truth yükle (varsa)
if os.path.exists(existing_gt_path):
    ground_truth_df = pd.read_excel(existing_gt_path)
    ground_truth_dict = dict(zip(ground_truth_df["Image Name"], ground_truth_df["Ground Truth"]))
    print("Mevcut ground truth yüklendi.")
else:
    ground_truth_dict = {}
    print("Ground truth bulunamadı. Manuel giriş yapılacak.")

# Görsel dosyalarını sırala
image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
print(f"Toplam {len(image_files)} görüntü işlenecek.")

# Görüntü ön işleme
def preprocess_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# Benzerlik oranı
def calculate_similarity(ground_truth, detected):
    return (1 - distance(ground_truth, detected) / max(len(ground_truth), len(detected))) * 100

# Sonuçları buraya ekleyeceğiz
final_ground_truth_list = []

# Görüntüler üzerinde çalış
for image_name in image_files:
    image_path = os.path.join(folder_path, image_name)
    image = cv2.imread(image_path)

    if image is None:
        print(f"{image_name} okunamadı, atlanıyor.")
        continue

    image_processed = preprocess_image(image)
    results = reader.readtext(image_processed)

    # OCR metinleri
    detected_texts = [res[1] for res in results]
    detected_texts = [dt.upper().strip() for dt in detected_texts if dt.strip()]

    # Görseli göster + bounding box
    for (bbox, text, confidence) in results:
        top_left = tuple(map(int, bbox[0]))
        bottom_right = tuple(map(int, bbox[2]))
        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
        cv2.putText(image, text, (top_left[0], top_left[1]-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

    # Görüntüyü göster
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(f"Image: {image_name}")
    plt.axis("off")


    # Ground truth varsa al, yoksa kullanıcıdan al
    if image_name in ground_truth_dict:
        gt_text = ground_truth_dict[image_name].upper().strip()
        print(f"Mevcut Ground Truth: {gt_text}")
    else:
        print(f"OCR Detected: {detected_texts}")
        gt_text = input(f"{image_name} için Ground Truth girin: ").upper().strip()

    plt.show()

    final_ground_truth_list.append({
        "Image Name": image_name,
        "Ground Truth": gt_text
    })

# Veriyi DataFrame'e dönüştür ve CSV olarak kaydet
final_df = pd.DataFrame(final_ground_truth_list)
final_df.to_csv(output_csv_path, index=False)
print(f"\n✅ Tüm bilgiler başarıyla kaydedildi: {output_csv_path}")